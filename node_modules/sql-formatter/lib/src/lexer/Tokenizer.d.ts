import { Token } from "./token";
import * as regexTypes from "./regexTypes";
interface TokenizerOptions {
    reservedCommands: string[];
    reservedLogicalOperators?: string[];
    reservedDependentClauses: string[];
    reservedBinaryCommands: string[];
    reservedJoins: string[];
    reservedJoinConditions?: string[];
    reservedKeywords: string[];
    stringTypes: regexTypes.QuoteType[];
    identTypes: regexTypes.QuoteType[];
    variableTypes?: regexTypes.VariableType[];
    openParens?: ('(' | '[' | '{')[];
    closeParens?: (')' | ']' | '}')[];
    positionalParams?: boolean;
    numberedParamTypes?: ('?' | ':' | '$')[];
    namedParamTypes?: (':' | '@' | '$')[];
    quotedParamTypes?: (':' | '@' | '$')[];
    lineCommentTypes?: string[];
    identChars?: regexTypes.IdentChars;
    paramChars?: regexTypes.IdentChars;
    operators?: string[];
    postProcess?: (tokens: Token[]) => Token[];
}
export default class Tokenizer {
    private engine;
    private postProcess?;
    constructor(cfg: TokenizerOptions);
    private validRules;
    tokenize(input: string): Token[];
}
export {};
