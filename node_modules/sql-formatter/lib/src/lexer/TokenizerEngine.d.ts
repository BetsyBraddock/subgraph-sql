import { Token, TokenType } from "./token";
export interface TokenRule {
    regex: RegExp;
    key?: (token: string) => string;
    value?: (token: string) => string;
}
export default class TokenizerEngine {
    private rules;
    private input;
    private index;
    constructor(rules: Partial<Record<TokenType, TokenRule>>);
    /**
     * Takes a SQL string and breaks it into tokens.
     * Each token is an object with type and value.
     *
     * @param {string} input - The SQL string
     * @returns {Token[]} output token stream
     */
    tokenize(input: string): Token[];
    private getWhitespace;
    private getNextToken;
    private matchPlaceholderToken;
    private matchReservedWordToken;
    private matchToken;
    private match;
}
